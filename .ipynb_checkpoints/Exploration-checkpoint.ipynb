{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22455e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "y_train, y_test = y_train[:, 0], y_test[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8196eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_indices = np.random.choice(range(len(y_train)), 10000, replace = False)\n",
    "#X_train, y_train = X_train[random_indices], y_train[random_indices]\n",
    "#indices_of_subclasses = np.where(y_train < 5)[0]\n",
    "#X_train, y_train = X_train[indices_of_subclasses], y_train[indices_of_subclasses]\n",
    "\n",
    "#random_indices = np.random.choice(range(len(y_test)), 1000, replace = False)\n",
    "#X_train, y_train = X_train[random_indices], y_train[random_indices]\n",
    "#random_indices = np.random.choice(range(len(y_test)), 500, replace = False)\n",
    "#X_test, y_test = X_test[random_indices], y_test[random_indices]\n",
    "#indices_of_subclasses = np.where(y_test < 5)[0]\n",
    "#X_test, y_test = X_test[indices_of_subclasses], y_test[indices_of_subclasses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca71a0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 11s 6ms/step - loss: 1.5104 - acc: 0.4768 - val_loss: 1.1850 - val_acc: 0.5862\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.1203 - acc: 0.6040 - val_loss: 0.9683 - val_acc: 0.6704\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.9573 - acc: 0.6622 - val_loss: 0.9859 - val_acc: 0.6538\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8400 - acc: 0.7077 - val_loss: 0.8285 - val_acc: 0.7280\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7361 - acc: 0.7420 - val_loss: 0.8045 - val_acc: 0.7278\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6561 - acc: 0.7699 - val_loss: 0.8604 - val_acc: 0.7106\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5847 - acc: 0.7927 - val_loss: 0.8365 - val_acc: 0.7258\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.5193 - acc: 0.8169 - val_loss: 0.8727 - val_acc: 0.7254\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4598 - acc: 0.8372 - val_loss: 0.7972 - val_acc: 0.7402\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.4130 - acc: 0.8552 - val_loss: 0.7422 - val_acc: 0.7594\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3768 - acc: 0.8662 - val_loss: 0.7323 - val_acc: 0.7732\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3403 - acc: 0.8798 - val_loss: 0.8124 - val_acc: 0.7602\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3129 - acc: 0.8903 - val_loss: 0.8236 - val_acc: 0.7516\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2843 - acc: 0.8989 - val_loss: 0.8286 - val_acc: 0.7642\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2643 - acc: 0.9072 - val_loss: 0.8431 - val_acc: 0.7636\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2502 - acc: 0.9110 - val_loss: 0.8505 - val_acc: 0.7566\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2316 - acc: 0.9188 - val_loss: 0.9194 - val_acc: 0.7568\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2239 - acc: 0.9217 - val_loss: 0.8277 - val_acc: 0.7702\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2062 - acc: 0.9266 - val_loss: 0.9933 - val_acc: 0.7354\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1969 - acc: 0.9313 - val_loss: 0.9510 - val_acc: 0.7384\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1899 - acc: 0.9336 - val_loss: 0.9548 - val_acc: 0.7452\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1776 - acc: 0.9379 - val_loss: 0.9207 - val_acc: 0.7656\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1752 - acc: 0.9383 - val_loss: 0.8871 - val_acc: 0.7644\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1680 - acc: 0.9410 - val_loss: 0.9048 - val_acc: 0.7592\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1635 - acc: 0.9421 - val_loss: 0.9130 - val_acc: 0.7696\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1545 - acc: 0.9467 - val_loss: 0.8494 - val_acc: 0.7724\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1519 - acc: 0.9480 - val_loss: 0.9411 - val_acc: 0.7664\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1415 - acc: 0.9504 - val_loss: 0.9631 - val_acc: 0.7604\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1462 - acc: 0.9486 - val_loss: 0.9426 - val_acc: 0.7674\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1414 - acc: 0.9499 - val_loss: 0.9011 - val_acc: 0.7766\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1285 - acc: 0.9554 - val_loss: 0.9173 - val_acc: 0.7728\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1261 - acc: 0.9570 - val_loss: 0.9644 - val_acc: 0.7598\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1312 - acc: 0.9537 - val_loss: 1.1274 - val_acc: 0.7484\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1208 - acc: 0.9576 - val_loss: 1.0170 - val_acc: 0.7604\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1262 - acc: 0.9556 - val_loss: 1.0558 - val_acc: 0.7602\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1141 - acc: 0.9596 - val_loss: 1.3686 - val_acc: 0.7090\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1143 - acc: 0.9600 - val_loss: 0.9827 - val_acc: 0.7692\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1112 - acc: 0.9613 - val_loss: 0.9637 - val_acc: 0.7744\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1092 - acc: 0.9613 - val_loss: 1.0180 - val_acc: 0.7652\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1075 - acc: 0.9616 - val_loss: 1.0583 - val_acc: 0.7608\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1081 - acc: 0.9615 - val_loss: 1.0223 - val_acc: 0.7592\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1035 - acc: 0.9636 - val_loss: 0.9593 - val_acc: 0.7748\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1084 - acc: 0.9620 - val_loss: 0.9554 - val_acc: 0.7754\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1049 - acc: 0.9635 - val_loss: 0.9366 - val_acc: 0.7824\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0948 - acc: 0.9669 - val_loss: 1.0232 - val_acc: 0.7688\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0986 - acc: 0.9655 - val_loss: 0.9841 - val_acc: 0.7742\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0968 - acc: 0.9669 - val_loss: 1.0094 - val_acc: 0.7742\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0955 - acc: 0.9668 - val_loss: 1.0494 - val_acc: 0.7680\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0911 - acc: 0.9686 - val_loss: 1.0484 - val_acc: 0.7738\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0916 - acc: 0.9679 - val_loss: 1.0484 - val_acc: 0.7616\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0924 - acc: 0.9681 - val_loss: 0.9791 - val_acc: 0.7716\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0852 - acc: 0.9707 - val_loss: 1.0833 - val_acc: 0.7610\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0885 - acc: 0.9692 - val_loss: 1.0070 - val_acc: 0.7706\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0891 - acc: 0.9699 - val_loss: 0.9887 - val_acc: 0.7726\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0774 - acc: 0.9739 - val_loss: 1.0085 - val_acc: 0.7756\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0855 - acc: 0.9706 - val_loss: 1.1686 - val_acc: 0.7508\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0836 - acc: 0.9715 - val_loss: 1.0045 - val_acc: 0.7774\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0820 - acc: 0.9714 - val_loss: 1.0581 - val_acc: 0.7720\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0808 - acc: 0.9724 - val_loss: 1.0811 - val_acc: 0.7738\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0797 - acc: 0.9730 - val_loss: 1.0377 - val_acc: 0.7640\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0831 - acc: 0.9710 - val_loss: 1.0947 - val_acc: 0.7724\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0747 - acc: 0.9746 - val_loss: 1.0709 - val_acc: 0.7722\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0733 - acc: 0.9741 - val_loss: 1.0294 - val_acc: 0.7758\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0781 - acc: 0.9729 - val_loss: 1.0369 - val_acc: 0.7682\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0757 - acc: 0.9736 - val_loss: 1.0393 - val_acc: 0.7720\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0766 - acc: 0.9726 - val_loss: 1.0553 - val_acc: 0.7708\n",
      "Epoch 67/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0732 - acc: 0.9745 - val_loss: 1.0299 - val_acc: 0.7778\n",
      "Epoch 68/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0715 - acc: 0.9755 - val_loss: 1.1453 - val_acc: 0.7566\n",
      "Epoch 69/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0674 - acc: 0.9769 - val_loss: 1.0237 - val_acc: 0.7750\n",
      "Epoch 70/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0737 - acc: 0.9741 - val_loss: 1.0623 - val_acc: 0.7730\n",
      "Epoch 71/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0662 - acc: 0.9767 - val_loss: 1.0491 - val_acc: 0.7734\n",
      "Epoch 72/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0713 - acc: 0.9753 - val_loss: 1.3753 - val_acc: 0.7370\n",
      "Epoch 73/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0683 - acc: 0.9767 - val_loss: 1.0424 - val_acc: 0.7750\n",
      "Epoch 74/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0708 - acc: 0.9754 - val_loss: 1.1108 - val_acc: 0.7700\n",
      "Epoch 75/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0642 - acc: 0.9773 - val_loss: 1.1426 - val_acc: 0.7642\n",
      "Epoch 76/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0692 - acc: 0.9761 - val_loss: 1.0770 - val_acc: 0.7692\n",
      "Epoch 77/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0655 - acc: 0.9772 - val_loss: 1.0551 - val_acc: 0.7788\n",
      "Epoch 78/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0639 - acc: 0.9786 - val_loss: 1.1590 - val_acc: 0.7696\n",
      "Epoch 79/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0639 - acc: 0.9791 - val_loss: 1.0105 - val_acc: 0.7858\n",
      "Epoch 80/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0646 - acc: 0.9776 - val_loss: 1.0566 - val_acc: 0.7746\n",
      "Epoch 81/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0645 - acc: 0.9775 - val_loss: 1.0732 - val_acc: 0.7752\n",
      "Epoch 82/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0609 - acc: 0.9798 - val_loss: 1.1161 - val_acc: 0.7632\n",
      "Epoch 83/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0609 - acc: 0.9790 - val_loss: 1.0894 - val_acc: 0.7732\n",
      "Epoch 84/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0636 - acc: 0.9783 - val_loss: 1.1285 - val_acc: 0.7736\n",
      "Epoch 85/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0570 - acc: 0.9805 - val_loss: 1.0766 - val_acc: 0.7810\n",
      "Epoch 86/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0608 - acc: 0.9795 - val_loss: 1.0987 - val_acc: 0.7792\n",
      "Epoch 87/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0618 - acc: 0.9786 - val_loss: 1.1182 - val_acc: 0.7706\n",
      "Epoch 88/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0599 - acc: 0.9796 - val_loss: 1.0690 - val_acc: 0.7788\n",
      "Epoch 89/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0569 - acc: 0.9804 - val_loss: 1.1146 - val_acc: 0.7746\n",
      "Epoch 90/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0536 - acc: 0.9814 - val_loss: 1.0665 - val_acc: 0.7798\n",
      "Epoch 91/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0550 - acc: 0.9811 - val_loss: 1.0695 - val_acc: 0.7796\n",
      "Epoch 92/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0569 - acc: 0.9810 - val_loss: 1.3930 - val_acc: 0.7364\n",
      "Epoch 93/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0585 - acc: 0.9805 - val_loss: 1.0921 - val_acc: 0.7720\n",
      "Epoch 94/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0557 - acc: 0.9817 - val_loss: 1.1310 - val_acc: 0.7672\n",
      "Epoch 95/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0530 - acc: 0.9817 - val_loss: 1.1154 - val_acc: 0.7706\n",
      "Epoch 96/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0542 - acc: 0.9809 - val_loss: 1.0467 - val_acc: 0.7882\n",
      "Epoch 97/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0551 - acc: 0.9815 - val_loss: 1.1636 - val_acc: 0.7716\n",
      "Epoch 98/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0542 - acc: 0.9815 - val_loss: 1.1085 - val_acc: 0.7776\n",
      "Epoch 99/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0540 - acc: 0.9817 - val_loss: 1.2443 - val_acc: 0.7686\n",
      "Epoch 100/100\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0537 - acc: 0.9818 - val_loss: 1.1119 - val_acc: 0.7720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53d87378b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.applications.resnet import ResNet50\n",
    "encoder = ResNet50(include_top = False, input_shape = np.shape(X_train)[1:])\n",
    "encoding_X_train = encoder.predict(X_train)[:, 0, 0, :]\n",
    "encoding_X_test = encoder.predict(X_test)[:, 0, 0, :]\n",
    "inp = keras.layers.Input(np.shape(encoding_X_train)[1:])\n",
    "\n",
    "x = keras.layers.Dense(128, activation = 'relu')(inp)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation = 'relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation = 'relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "cls_logits = keras.layers.Dense(units=len(np.unique(y_train)), activation = 'linear')(x)\n",
    "cls_out = keras.layers.Activation('softmax', name = 'cls_out')(cls_logits)\n",
    "\n",
    "network = keras.models.Model(inputs = inp, outputs = cls_out)\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "          optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "          metrics = ['acc'])\n",
    "network.fit(encoding_X_train, keras.utils.to_categorical(y_train), \n",
    "    epochs = 25,\n",
    "    verbose = 1,\n",
    "    validation_split = .1)\n",
    "'''\n",
    "#load and train model \n",
    "inp = keras.layers.Input(np.shape(X_train)[1:])\n",
    "\n",
    "x = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(inp)\n",
    "x = keras.layers.MaxPooling2D()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D()(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "\n",
    "x = keras.layers.Dense(units=1024, activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(units=512, activation='relu')(x)\n",
    "enc = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "cls_logits = keras.layers.Dense(units=len(np.unique(y_train)), activation = 'linear')(enc)\n",
    "cls_out = keras.layers.Activation('softmax', name = 'cls_out')(cls_logits)\n",
    "\n",
    "network = keras.models.Model(inputs = inp, outputs = cls_out)\n",
    "encoder = keras.models.Model(inputs = inp, outputs = enc)\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "          optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "          metrics = ['acc'])\n",
    "network.fit(X_train, keras.utils.to_categorical(y_train), \n",
    "    epochs = 100,\n",
    "    verbose = 1,\n",
    "    validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb6f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_X_train = encoder.predict(X_train).reshape(X_train.shape[0], -1)\n",
    "encoding_X_test = encoder.predict(X_test).reshape(X_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b416d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_means, class_95, class_100, class_105 = [], [], [], []\n",
    "for c in range(len(np.unique(y_train))):\n",
    "    examples_of_class = np.where(y_train == c)[0]\n",
    "    class_means.append(np.mean(encoding_X_train[examples_of_class], axis = 0))\n",
    "    class_95.append(np.percentile(np.sqrt(np.sum(encoding_X_train[examples_of_class] ** 2, axis = 1)), 95))\n",
    "    class_100.append(np.percentile(np.sqrt(np.sum(encoding_X_train[examples_of_class] ** 2, axis = 1)), 100))\n",
    "    class_105.append(class_100[-1] + (class_100[-1] - class_95[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ae6a42cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal as mv\n",
    "vos_samples = []\n",
    "for c in tqdm(range(len(np.unique(y_train)))):\n",
    "    examples_of_class = np.where(y_train == c)[0]\n",
    "    vos_samples_of_class = mv.rvs(mean = 0, cov = 1, size = (int(len(examples_of_class) / 3), np.shape(encoding_X_train)[1]))\n",
    "    vos_samples_of_class = vos_samples_of_class / np.linalg.norm(vos_samples_of_class, axis =1)[:, np.newaxis]\n",
    "    magnitudes = np.random.uniform(class_95[c], class_105[c], size = len(vos_samples_of_class))\n",
    "    vos_samples_of_class = class_means[c] + vos_samples_of_class * class_105[c]#* magnitudes[:, np.newaxis]\n",
    "    vos_samples.extend(vos_samples_of_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d1703fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_X_train = np.concatenate([encoding_X_train, vos_samples], axis = 0)\n",
    "ood_y_train = np.concatenate([keras.utils.to_categorical(y_train), np.ones((len(vos_samples), len(np.unique(y_train)))) / len(np.unique(y_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "32101551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1567.6945 - val_loss: 42.3173\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 74.0113 - val_loss: 35.3236\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 56.0045 - val_loss: 28.0177\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 34.3625 - val_loss: 23.5703\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 22.2798 - val_loss: 17.3852\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 13.9903 - val_loss: 14.0071\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 5.9524 - val_loss: 11.0353\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 3.5281 - val_loss: 9.5265\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1527 - val_loss: 7.6051\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5610 - val_loss: 6.0843\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1565 - val_loss: 4.9807\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9337 - val_loss: 4.2387\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8295 - val_loss: 3.8130\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7652 - val_loss: 3.4491\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7092 - val_loss: 3.1942\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6705 - val_loss: 3.0933\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6536 - val_loss: 3.0612\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6368 - val_loss: 3.0167\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6294 - val_loss: 3.0018\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6197 - val_loss: 3.0135\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6166 - val_loss: 3.0132\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6103 - val_loss: 3.0233\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6048 - val_loss: 3.0336\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5984 - val_loss: 2.9891\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5963 - val_loss: 2.9712\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5916 - val_loss: 2.9865\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5880 - val_loss: 2.9673\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5863 - val_loss: 2.9620\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5832 - val_loss: 2.9496\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5799 - val_loss: 2.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f53106ab3a0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = keras.layers.Dense(100, activation = 'relu')(enc)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "pre_temperature = keras.layers.Dense(units = 1, activation = 'linear')(x)\n",
    "#custom loss. We want the temperature to be unbounded on the positive side (and therefore when the pretemperature is greater than 0, it's unbounded; \n",
    "#but we also need to make sure the temperature is never negative - so we don't get infinite logits. So we do an exponentially decaying activation on the negative side)\n",
    "temperature = keras.layers.Activation(lambda v : tf.where(v < 0, keras.activations.exponential(v), 1 + keras.activations.linear(v)))(pre_temperature)\n",
    "ood_cls_logits = keras.layers.Lambda(lambda inputs: inputs[0] / inputs[1])([cls_logits, temperature])\n",
    "ood_cls_out = keras.layers.Activation('softmax')(ood_cls_logits)\n",
    "\n",
    "temperature_model = keras.models.Model(inputs = enc, outputs = temperature)\n",
    "ood_network = keras.models.Model(inputs = enc, outputs = ood_cls_out)\n",
    "for layer in network.layers:\n",
    "    layer.trainable = False\n",
    "ood_network.compile(loss='categorical_crossentropy',\n",
    "          optimizer=keras.optimizers.Adam(learning_rate=3e-4))\n",
    "ood_network.fit(ood_X_train, ood_y_train, \n",
    "    epochs = 30,\n",
    "    verbose = 1,\n",
    "    validation_split = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5159ade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Distribution Temperature:  2.2026253\n"
     ]
    }
   ],
   "source": [
    "t = temperature_model.predict(encoding_X_train)\n",
    "print(\"In Distribution Temperature: \", np.mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9d2629d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD Temperature (we want this to be much higher than the in distribution temperature):  18.314945\n"
     ]
    }
   ],
   "source": [
    "t = temperature_model.predict(np.array(vos_samples))\n",
    "print(\"OOD Temperature (we want this to be much higher than the in distribution temperature): \", np.mean(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c8dc85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Deflated OOD Confidence Average (we want this to be really low):  0.36736196\n"
     ]
    }
   ],
   "source": [
    "pred = ood_network.predict(np.array(vos_samples))\n",
    "print(\"Temperature Deflated OOD Confidence Average (we want this to be really low): \", np.mean(np.max(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b0e7a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Deflated In-Distribution Confidence Average:  0.9551377\n"
     ]
    }
   ],
   "source": [
    "pred = ood_network.predict(encoding_X_train)\n",
    "print(\"Temperature Deflated In-Distribution Confidence Average: \", np.mean(np.max(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f29c5b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaffected Model OOD Confidence Average (this being high shows networks are overconfident OOD):  0.9480723\n"
     ]
    }
   ],
   "source": [
    "pred = keras.models.Model(inputs = enc, outputs = cls_out).predict(np.array(vos_samples))\n",
    "print(\"Unaffected Model OOD Confidence Average (this being high shows networks are overconfident OOD): \", np.mean(np.max(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fbe9795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unaffected Model In-Distribution Confidence Average:  0.9906954\n"
     ]
    }
   ],
   "source": [
    "pred = network.predict(X_train)\n",
    "print(\"Unaffected Model In-Distribution Confidence Average: \", np.mean(np.max(pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3a516436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ece(confidences, correctness):\n",
    "    hists = []\n",
    "    hists_hat = []\n",
    "    amts = []\n",
    "    num_bins = 100\n",
    "    for i in range(num_bins):\n",
    "        prop = i*1./num_bins\n",
    "        inds = np.where((confidences >= prop) & (confidences <= prop+1./num_bins))[0]\n",
    "        amts.append(len(inds))\n",
    "        if len(inds) > 0:\n",
    "            hists.append(len(np.where(correctness[inds] == 1)[0])*1./len(inds))\n",
    "            hists_hat.append(np.mean(confidences[inds]))\n",
    "        else:\n",
    "            hists.append(prop)\n",
    "            hists_hat.append(prop + 0.5/num_bins)\n",
    "    return np.sum(np.abs(np.array(hists) - np.array(hists_hat)) * np.array(amts)) / np.sum(amts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "51ac62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8422910368552128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03537729550633123"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "pred = network.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(np.argmax(pred, axis = 1) == y_test, np.max(pred, axis = 1)))\n",
    "class_eces = []\n",
    "for j in range(len(np.unique(y_train))):\n",
    "    class_eces.append(get_ece(np.array(pred)[:, j], y_test == j))\n",
    "np.mean(class_eces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1af5916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8437897588946405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019492671695147873"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ood_network.predict(encoding_X_test)\n",
    "print(roc_auc_score(np.argmax(pred, axis = 1) == y_test, np.max(pred, axis = 1)))\n",
    "class_eces = []\n",
    "for j in range(len(np.unique(y_train))):\n",
    "    class_eces.append(get_ece(np.array(pred)[:, j], y_test == j))\n",
    "np.mean(class_eces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9f39a436",
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_scores_test = temperature_model.predict(encoding_X_test)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f2ddc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = network.predict(X_test)\n",
    "ood_model_predictions = ood_network.predict(encoding_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "576460f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_intervals = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6a67deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#z_scores = p_label_error / (variance_confidences + 1e-12)\n",
    "from sklearn.metrics import average_precision_score\n",
    "order = np.argsort(ood_scores_test)[::-1]\n",
    "ps = []\n",
    "accs = []\n",
    "base_eces = []\n",
    "ood_model_eces = []\n",
    "\n",
    "for i in range(0, len(y_test), int(len(y_test) / num_intervals)):\n",
    "    class_eces = []\n",
    "    for j in range(len(np.unique(y_train))):\n",
    "        class_eces.append(get_ece(np.array(model_predictions)[order[:i + int(len(y_test) / num_intervals)], j], (y_test[order[:i + int(len(y_test) / num_intervals)]] == j)))\n",
    "    base_eces.append(np.median(class_eces))\n",
    "\n",
    "    class_eces = []\n",
    "    for j in range(len(np.unique(y_train))):\n",
    "        class_eces.append(get_ece(np.array(ood_model_predictions)[order[:i + int(len(y_test) / num_intervals)], j], (y_test[order[:i + int(len(y_test) / num_intervals)]] == j)))\n",
    "    ood_model_eces.append(np.median(class_eces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7f0f7685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5310f43d90>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.plot(ood_scores_test[order[np.arange(0, len(y_test), int(len(y_test) / num_intervals))]], base_eces, label = \"Unchanged Model\")\n",
    "plt.plot(np.arange(0, len(y_test), int(len(y_test) / num_intervals)) / len(y_test), base_eces, label = \"Unchanged Model\")\n",
    "#plt.plot(ood_scores_test[order[np.arange(0, len(y_test), int(len(y_test) / num_intervals))]], ood_model_eces, label = \"Penultimate-Dependent Temperature Deflation Model\")\n",
    "plt.plot(np.arange(0, len(y_test), int(len(y_test) / num_intervals)) / len(y_test), ood_model_eces, label = \"Penultimate-Dependent Temperature Deflation Model\")\n",
    "plt.xlabel(\"In-Distribution Score (Inverse Temperature)\")\n",
    "plt.ylabel(\"ECE Of Accepted Points\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43413d",
   "metadata": {},
   "source": [
    "The blue line decreasing shows that we can measure when the model has low ECE (when the temperature is high - or inverse temperature is low)\n",
    "\n",
    "The orange line being lower shows that this penultimate-dependent temperature lowers ECE, which is potentially lowered even further by training to uniform confidence on the Virtual Outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
